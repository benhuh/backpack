{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbackpackcondab2d8ac08d968404180c6f48692f1de3a",
   "display_name": "Python 3.7.6 64-bit ('backpack': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_data' from 'backpack.utils' (/Users/huh/Projects/sNGD_projects/backpack/libraries/backpack/backpack/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1bf466ddd145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbackpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbackpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbackpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_data' from 'backpack.utils' (/Users/huh/Projects/sNGD_projects/backpack/libraries/backpack/backpack/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from backpack import backpack\n",
    "from backpack.extensions import KFAC\n",
    "from backpack.utils import load_data\n",
    "\n",
    "X, y = load_data()\n",
    "\n",
    "loss = lossfunc(model(X), y)\n",
    "\n",
    "with backpack(KFAC()):\n",
    "        loss.backward()\n",
    "\n",
    "        for param in model.parameters():\n",
    "                print(param.grad)\n",
    "                print(param.kfac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5ccfee44b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mbackpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKFAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(764, 64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 10)\n",
    ")\n",
    "lossfunc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "from backpack import extend\n",
    "\n",
    "model = extend(model)\n",
    "lossfunc = extend(lossfunc)\n",
    "\n",
    "\n",
    "loss = lossfunc(model(X), y)\n",
    "\n",
    "with backpack(KFAC()):\n",
    "        loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "print\ntorch.Size([64, 10, 1])\n"
    },
    {
     "ename": "RuntimeError",
     "evalue": "prob_dist must be 1 or 2 dim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e665183ef0c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDiagGGNMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/backpack/lib/python3.7/site-packages/torch-1.4.0-py3.7-macosx-10.9-x86_64.egg/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/backpack/lib/python3.7/site-packages/torch-1.4.0-py3.7-macosx-10.9-x86_64.egg/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/sNGD_projects/backpack/libraries/backpack/backpack/__init__.py\u001b[0m in \u001b[0;36mrun_extensions\u001b[0;34m(module_, g_inp, g_out)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;34m\"on\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 )\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mbackpack_extension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mextension_contain_curvmatprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/sNGD_projects/backpack/libraries/backpack/backpack/extensions/backprop_extension.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, module, g_inp, g_out)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mmodule_extension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_module_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mmodule_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/sNGD_projects/backpack/libraries/backpack/backpack/extensions/module_extension.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, ext, module, g_inp, g_out)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         bpQuantities = self.backpropagate(\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpQuantities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/sNGD_projects/backpack/libraries/backpack/backpack/extensions/secondorder/diag_ggn/losses.py\u001b[0m in \u001b[0;36mbackpropagate\u001b[0;34m(self, ext, module, grad_inp, grad_out, backproped)\u001b[0m\n\u001b[1;32m     18\u001b[0m             )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhess_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/sNGD_projects/backpack/libraries/backpack/backpack/core/derivatives/crossentropyloss.py\u001b[0m in \u001b[0;36msqrt_hessian_sampled\u001b[0;34m(self, module, g_inp, g_out)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         classes = one_hot(multinomial(probs, M, replacement=True),\n\u001b[0m\u001b[1;32m     42\u001b[0m                           num_classes=C)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: prob_dist must be 1 or 2 dim"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Quick example: A small second-order optimizer with BackPACK\n",
    "on the classic MNIST example from PyTorch,\n",
    "https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "The optimizer we implement uses a constant damping parameter\n",
    "and uses the diagonal of the GGN/Fisher matrix as a preconditioner;\n",
    "\n",
    "```\n",
    "x_{t+1} = x_t - (G_t + bI)^{-1} g_t\n",
    "```\n",
    "\n",
    "- `x_t` are the parameters of the model\n",
    "- `G_t` is the diagonal of the Gauss-Newton/Fisher matrix at `x_t`\n",
    "- `b` is a damping parameter\n",
    "- `g_t` is the gradient\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "# The main BackPACK functionalities\n",
    "from backpack import backpack, extend\n",
    "# The diagonal GGN extension\n",
    "from backpack.extensions import DiagGGNMC\n",
    "# This layer did not exist in Pytorch 1.0\n",
    "from backpack.core.layers import Flatten\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "STEP_SIZE = 0.01\n",
    "DAMPING = 1.0\n",
    "MAX_ITER = 100\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 1: Load data and create the model.\n",
    "\n",
    "We're going to load the MNIST dataset,\n",
    "and fit a 3-layer MLP with ReLU activations.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "mnist_loader = torch.utils.data.dataloader.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        './data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                (0.1307,), (0.3081,)\n",
    "            )\n",
    "        ])),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 20, 5, 1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Conv2d(20, 50, 5, 1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    Flatten(), \n",
    "    # Pytorch <1.2 doesn't have a Flatten layer\n",
    "    torch.nn.Linear(4*4*50, 500),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(500, 10),\n",
    ")\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def get_accuracy(output, targets):\n",
    "    \"\"\"Helper function to print the accuracy\"\"\"\n",
    "    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n",
    "    return predictions.eq(targets).float().mean().item()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 2: Create the optimizer.\n",
    "\n",
    "After we call the backward pass with backpack,\n",
    "every parameter will have a `diag_ggn_mc` field\n",
    "in addition to a `grad` field.\n",
    "\n",
    "We can use it to compute the search direction for that parameter,\n",
    "```\n",
    "step_direction = p.grad / (p.diag_ggn_mc + group[\"damping\"])\n",
    "```\n",
    "and update the weights\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class DiagGGNOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self, parameters, step_size, damping):\n",
    "        super().__init__(\n",
    "            parameters, \n",
    "            dict(step_size=step_size, damping=damping)\n",
    "        )\n",
    "\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                step_direction = p.grad / (p.diag_ggn_mc + group[\"damping\"])\n",
    "                p.data.add_(-group[\"step_size\"], step_direction)\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 3: Tell BackPACK about the model and loss function, \n",
    "create the optimizer, and we will be ready to go\n",
    "\"\"\"\n",
    "\n",
    "extend(model)\n",
    "extend(loss_function)\n",
    "\n",
    "optimizer = DiagGGNOptimizer(\n",
    "    model.parameters(), \n",
    "    step_size=STEP_SIZE, \n",
    "    damping=DAMPING\n",
    ")\n",
    "\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(), \n",
    "#     lr=0.01\n",
    "# )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Final step: The training loop!\n",
    "\n",
    "The only difference with a traditional training loop:\n",
    "Before calling the backward pass, we will call\n",
    "```\n",
    "    with backpack(DiagGGNMC()):\n",
    "```\n",
    "BackPACK will then add the diagonal of the GGN in the\n",
    "`diag_ggn_mc` field during the backward pass.\n",
    "\"\"\"\n",
    "\n",
    "print('print')\n",
    "\n",
    "\n",
    "for batch_idx, (x, y) in enumerate(mnist_loader):\n",
    "    output = model(x)\n",
    "\n",
    "    accuracy = get_accuracy(output, y)\n",
    "\n",
    "    with backpack(DiagGGNMC()):\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\n",
    "        \"Iteration %3.d/%d   \" % (batch_idx, MAX_ITER) +\n",
    "        \"Minibatch Loss %.3f  \" % (loss) +\n",
    "        \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "    )\n",
    "\n",
    "    if batch_idx >= MAX_ITER:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}